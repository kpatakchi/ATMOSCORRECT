{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1404b983-2d06-4560-a86b-5570d0169ea0",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "## Prepare the training data:\n",
    "\n",
    "Scripts for \n",
    "- Reading the datasets (model and reference)\n",
    "- Aligning the datasets in time and calculating the mismatch (if needed).\n",
    "- Masking the na values (also other masks if needed)\n",
    "- Making perfect square/rectangular shaped canvas for UNet\n",
    "- ID (data_unique_name) the training data and save it\n",
    "\n",
    "Output:\n",
    "- canvas_x, canvas_y, and canvas_m used in training the network saved as train_data.npz (canvas_x is the input data, canvas_y is the output and canvas_m are the weights for training)\n",
    "\n",
    "What needs to be defined?\n",
    "- Data pairs e.g. REFERENCE-MODEL or TSMP-COSMO\n",
    "- Remap_type, which remapping method (e.g., remapbil)\n",
    "- task_name (model-only, model-lag, temporal, spatiotemporal, spatial)\n",
    "- Boundary parameters, what are the pixup, pixright, xpix, ypix?\n",
    "- Number of channels\n",
    "- Mapping method, direct mapping or mismatch mapping?\n",
    "- Boxparameters for preparing the data for UNET.\n",
    "\n",
    "Areas of improvement (to be developed):\n",
    "\n",
    "- Dealing with negative values in MODEL. \n",
    "- Dealing with time- and coordinate-alignment issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab2222f-cad0-4047-b807-733d41193fbc",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_hourly.pr.['HRES'].['HSAF'].MM.6..spatiotemporal.128.256.2020-10-01.2021-09-30.no_na.npz\n"
     ]
    }
   ],
   "source": [
    "from py_env_hpc import *\n",
    "\n",
    "# Define the following:\n",
    "model_data = [\"HRES\"] # TSMP must come first for calculating the mismatch correctly in ensembles!!!\n",
    "reference_data = [\"HSAF\"]\n",
    "task_name = \"spatiotemporal\"\n",
    "mm = \"MM\"  # or DM\n",
    "date_start=\"2020-10-01\"\n",
    "date_end=\"2021-09-30\"\n",
    "variable=\"pr\"\n",
    "mask_type=\"no_na\"\n",
    "laginensemble=False\n",
    "\n",
    "# The following is defined automatically:\n",
    "n_ensembles = len(model_data)\n",
    "n_channels = Func.calculate_channels(n_ensembles, task_name, laginensemble=laginensemble)\n",
    "if reference_data == [\"COSMO_REA6\"]:\n",
    "    canvas_size = (400, 400) \n",
    "    topo_dir='/p/project/deepacf/kiste/patakchiyousefi1/IO/03-TOPOGRAPHY/EU-11-TOPO.npz'\n",
    "    trim=True\n",
    "    daily=True\n",
    "if reference_data == [\"HSAF\"]:\n",
    "    topo_dir='/p/project/deepacf/kiste/patakchiyousefi1/IO/03-TOPOGRAPHY/HSAF-TOPO.npz'\n",
    "    canvas_size = (128, 256)\n",
    "    trim=False\n",
    "    daily=False\n",
    "data_unique_name = f\"train_data{'_daily' if daily else '_hourly'}.{variable}.{model_data}.{reference_data}.{mm}.{n_channels}.{'laginensemble' if laginensemble else ''}.{task_name}.{'.'.join(map(str, canvas_size))}.{date_start}.{date_end}.{mask_type}\"\n",
    "filename = f\"{data_unique_name}.npz\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029c6513-2c6d-4b45-a8c8-aae76f11159c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "locked": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data generated\n"
     ]
    }
   ],
   "source": [
    "if filename not in os.listdir(TRAIN_FILES):\n",
    "\n",
    "    # 1) Open the datasets:\n",
    "    datasets = []\n",
    "    for model in model_data:\n",
    "        dataset = xarray.open_dataset(f\"{ATMOS_DATA}/{model}_{variable}.nc\")\n",
    "        dataset = dataset[variable].sel(time=slice(date_start, date_end))\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    REFERENCE = xarray.open_dataset(f\"{ATMOS_DATA}/{reference_data[0]}_{variable}.nc\")\n",
    "    REFERENCE = REFERENCE[variable].sel(time=slice(date_start, date_end))\n",
    "    \n",
    "    # 2) Align time-wise and calculate the mismatch\n",
    "    for i, model in enumerate(datasets):\n",
    "        datasets[i][\"time\"] = datasets[i][\"time\"].astype(REFERENCE[\"time\"].dtype)\n",
    "        if reference_data == [\"HSAF\"]:\n",
    "            REFERENCE=REFERENCE.where(REFERENCE['time'].isin(datasets[i]['time']),  drop=True)\n",
    "            datasets[i]=datasets[i].where(datasets[i]['time'].isin(REFERENCE['time']),  drop=True)\n",
    "        datasets[i], REFERENCE = xarray.align(datasets[i], REFERENCE, join=\"override\")\n",
    "    \n",
    "    # Calculate calendar data according to REFERENCE (starting the calendar one day later)\n",
    "    dayofyear=REFERENCE[1:, ...].time.dt.dayofyear.values\n",
    "    dayofyear_resh = np.tile(dayofyear[:, np.newaxis, np.newaxis], (1, REFERENCE[1:, ...].shape[1], REFERENCE[1:, ...].shape[2]))\n",
    "    yeardate=REFERENCE[1:, ...].time.dt.year.values\n",
    "    yeardate_resh = np.tile(yeardate[:, np.newaxis, np.newaxis], (1, REFERENCE[1:, ...].shape[1], REFERENCE[1:, ...].shape[2]))\n",
    "    CAL = np.stack((dayofyear_resh, yeardate_resh), axis=3)\n",
    "    \n",
    "    REFERENCE = REFERENCE.values[:, :, :, np.newaxis] # add new axis along ensemble dimension\n",
    "    datasets = [dataset.values for dataset in datasets]\n",
    "    MODEL = np.stack(datasets, axis=-1)\n",
    "    if len(datasets)>1:\n",
    "        TARGET = (MODEL[0] - REFERENCE) if (mm == \"MM\") else REFERENCE\n",
    "    else:\n",
    "        TARGET = (MODEL - REFERENCE) if (mm == \"MM\") else REFERENCE\n",
    "    if MODEL.shape[0] < 1:\n",
    "        print(\"The selected dates doesn't exist in the netcdf files!\")\n",
    "        \n",
    "    # 3) prepare dim-wise:\n",
    "    Y_TRAIN = TARGET[1:, ...]  # t\n",
    "    X_TRAIN = MODEL[1:, ...] # t\n",
    "    canvas_y = Func.make_canvas(Y_TRAIN, canvas_size, trim)\n",
    "    canvas_y = np.nan_to_num(canvas_y, nan=-999) #fill values\n",
    "\n",
    "    if mask_type == \"no_na\":\n",
    "        canvas_m = np.zeros_like(canvas_y) #mask for na values (-999)\n",
    "        canvas_m[canvas_y != -999] = 1.0\n",
    "\n",
    "    if task_name == \"model-lag\":\n",
    "        X_TRAIN_tminus = np.expand_dims(MODEL[variable].values, axis=3)[:-1, ...] # t-1\n",
    "        X_TRAIN = np.concatenate ((X_TRAIN_tminus, X_TRAIN), axis=3)\n",
    "        \n",
    "    if task_name == \"temporal\":\n",
    "        X_TRAIN = np.concatenate((X_TRAIN, CAL), axis=3)\n",
    "    \n",
    "    if task_name == \"spatial\":\n",
    "        SPP = Func.spatiodataloader(topo_dir, X_TRAIN.shape)\n",
    "        X_TRAIN = np.concatenate((X_TRAIN, SPP), axis=3)\n",
    "        \n",
    "    if task_name == \"spatiotemporal\":\n",
    "        SPP = Func.spatiodataloader(topo_dir, X_TRAIN.shape)\n",
    "        X_TRAIN = np.concatenate((X_TRAIN, CAL, SPP), axis=3)\n",
    "    \n",
    "    canvas_x = Func.make_canvas(X_TRAIN, canvas_size, trim)  \n",
    "    np.savez(TRAIN_FILES + \"/\" + filename, canvas_x=canvas_x, canvas_y=canvas_y, canvas_m=canvas_m)\n",
    "    print(\"data generated\")\n",
    "else:\n",
    "    print(\"the data with the same unique name is already available\")"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "prc_env",
   "language": "python",
   "name": "conda_prc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

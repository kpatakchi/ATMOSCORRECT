{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34102b9-6c6a-4f30-b4de-669d3121c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_hourly.pr.['HRES'].['HSAF'].MM.6..spatiotemporal.128.256.2020-07-01T13.2023-03-26T23.no_na mse.32.0.01.0.0001.0.25.2.2.8.0.1.64\n",
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 15:37:50.688776: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-24 15:37:50.874391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:50.874862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:50.875277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:50.875672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:50.875714: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-06-24 15:37:51.266729: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-06-24 15:37:51.266802: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-06-24 15:37:51.359562: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-24 15:37:51.491308: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-24 15:37:51.607043: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-06-24 15:37:51.677797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-06-24 15:37:51.723094: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-06-24 15:37:51.726224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-06-24 15:37:52.097623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:52.098076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:52.098466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:52.098856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.74GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-24 15:37:52.101718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2023-06-24 15:37:52.101799: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-06-24 15:37:55.565479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-24 15:37:55.565517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \n",
      "2023-06-24 15:37:55.565523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y Y \n",
      "2023-06-24 15:37:55.565533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y Y \n",
      "2023-06-24 15:37:55.565538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N Y \n",
      "2023-06-24 15:37:55.565542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   Y Y Y N \n",
      "2023-06-24 15:37:55.569386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31013 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)\n",
      "2023-06-24 15:37:55.620120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 31013 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n",
      "2023-06-24 15:37:55.620821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 31013 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n",
      "2023-06-24 15:37:55.621904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 31013 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)\n",
      "2023-06-24 15:37:55.622235: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-06-24 15:37:56.230344: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-06-24 15:37:56.230383: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-06-24 15:37:56.230463: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 4 GPUs\n",
      "2023-06-24 15:37:56.281837: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.3\n",
      "2023-06-24 15:37:56.998731: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-06-24 15:37:56.998958: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 15:38:08.302138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-06-24 15:38:08.314483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 15:38:10.200626: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-06-24 15:38:12.377582: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-06-24 15:38:16.870000: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-06-24 15:38:19.633890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/10781 [..............................] - ETA: 40:12:11 - loss: 1.3392 - mse: 533413.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 15:38:22.182656: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-06-24 15:38:22.182695: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3/10781 [..............................] - ETA: 1:46:28 - loss: 5.0166 - mse: 298184.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 15:38:22.885858: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-06-24 15:38:22.886246: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2023-06-24 15:38:22.974730: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 521 callback api events and 518 activity events. \n",
      "2023-06-24 15:38:22.983767: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-06-24 15:38:23.009159: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22\n",
      "2023-06-24 15:38:23.016573: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.trace.json.gz\n",
      "2023-06-24 15:38:23.040023: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22\n",
      "2023-06-24 15:38:23.046096: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.memory_profile.json.gz\n",
      "2023-06-24 15:38:23.051990: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22Dumped tool data for xplane.pb to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64/train/plugins/profile/2023_06_24_15_38_22/hdfmlc01.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10781/10781 [==============================] - 151s 13ms/step - loss: 0.1172 - mse: 224450.7656 - val_loss: 0.1200 - val_mse: 214377.9375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12002, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 2/64\n",
      "10781/10781 [==============================] - 134s 12ms/step - loss: 0.1091 - mse: 224450.9531 - val_loss: 0.1163 - val_mse: 214397.7969\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12002 to 0.11628, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 3/64\n",
      "10781/10781 [==============================] - 134s 12ms/step - loss: 0.1065 - mse: 224451.3594 - val_loss: 0.1152 - val_mse: 214398.7031\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11628 to 0.11518, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 4/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.1048 - mse: 224452.0938 - val_loss: 0.1169 - val_mse: 214405.2344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11518\n",
      "Epoch 5/64\n",
      "10781/10781 [==============================] - 133s 12ms/step - loss: 0.1038 - mse: 224451.9219 - val_loss: 0.1171 - val_mse: 214412.0156\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11518\n",
      "Epoch 6/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.1003 - mse: 224452.0625 - val_loss: 0.1153 - val_mse: 214416.9688\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11518\n",
      "Epoch 7/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0995 - mse: 224452.6094 - val_loss: 0.1192 - val_mse: 214412.7969\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11518\n",
      "Epoch 8/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0980 - mse: 224452.3281 - val_loss: 0.1153 - val_mse: 214405.7969\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11518\n",
      "Epoch 9/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0977 - mse: 224452.3750 - val_loss: 0.1162 - val_mse: 214414.0625\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11518\n",
      "Epoch 10/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0971 - mse: 224451.6406 - val_loss: 0.1149 - val_mse: 214412.5938\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11518 to 0.11494, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 11/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0971 - mse: 224451.9531 - val_loss: 0.1151 - val_mse: 214414.1719\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11494\n",
      "Epoch 12/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0970 - mse: 224452.9375 - val_loss: 0.1159 - val_mse: 214411.6875\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.11494\n",
      "Epoch 13/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0968 - mse: 224451.6562 - val_loss: 0.1152 - val_mse: 214412.9062\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.11494\n",
      "Epoch 14/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0967 - mse: 224452.5156 - val_loss: 0.1146 - val_mse: 214412.6719\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.11494 to 0.11462, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 15/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0967 - mse: 224452.2344 - val_loss: 0.1165 - val_mse: 214414.6094\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11462\n",
      "Epoch 16/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0966 - mse: 224452.5000 - val_loss: 0.1162 - val_mse: 214412.5312\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.11462\n",
      "Epoch 17/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0966 - mse: 224451.9062 - val_loss: 0.1163 - val_mse: 214411.9219\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11462\n",
      "Epoch 18/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0966 - mse: 224451.5625 - val_loss: 0.1150 - val_mse: 214412.3281\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11462\n",
      "Epoch 19/64\n",
      "10781/10781 [==============================] - 135s 13ms/step - loss: 0.0965 - mse: 224452.5156 - val_loss: 0.1146 - val_mse: 214411.0469\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.11462 to 0.11458, saving model to /p/project/deepacf/kiste/patakchiyousefi1/AI MODELS/00-UNET/mse.32.0.01.0.0001.0.25.2.2.8.0.1.64.h5\n",
      "Epoch 20/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0963 - mse: 224452.2031 - val_loss: 0.1147 - val_mse: 214410.6094\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11458\n",
      "Epoch 21/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0962 - mse: 224451.8281 - val_loss: 0.1148 - val_mse: 214411.4688\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11458\n",
      "Epoch 22/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0962 - mse: 224452.2969 - val_loss: 0.1156 - val_mse: 214411.5625\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11458\n",
      "Epoch 23/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0963 - mse: 224451.9062 - val_loss: 0.1158 - val_mse: 214412.6562\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11458\n",
      "Epoch 24/64\n",
      "10781/10781 [==============================] - 133s 12ms/step - loss: 0.0960 - mse: 224452.3750 - val_loss: 0.1155 - val_mse: 214414.4062\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11458\n",
      "Epoch 25/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0960 - mse: 224451.7031 - val_loss: 0.1155 - val_mse: 214413.5938\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11458\n",
      "Epoch 26/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0960 - mse: 224452.4062 - val_loss: 0.1165 - val_mse: 214415.1406\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11458\n",
      "Epoch 27/64\n",
      "10781/10781 [==============================] - 132s 12ms/step - loss: 0.0959 - mse: 224452.5938 - val_loss: 0.1155 - val_mse: 214411.5156\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11458\n",
      "Saving and plotting the results...\n"
     ]
    }
   ],
   "source": [
    "from py_env_train import *\n",
    "\n",
    "# Define the data specifications:\n",
    "model_data = [\"HRES\"]\n",
    "reference_data = [\"HSAF\"]\n",
    "task_name = \"spatiotemporal\"\n",
    "mm = \"MM\"  # or DM\n",
    "date_start=\"2020-07-01T13\"\n",
    "date_end=\"2023-03-26T23\"\n",
    "variable = \"pr\"\n",
    "mask_type = \"no_na\"\n",
    "laginensemble = False\n",
    "\n",
    "# Define the following for network configs:\n",
    "loss=\"mse\"\n",
    "Filters=32\n",
    "#LR=0.01\n",
    "min_LR=0.0001\n",
    "#BS=2\n",
    "lr_patience=2\n",
    "patience=8\n",
    "#lr_factor=0.25\n",
    "epochs=64\n",
    "val_split=0.2\n",
    "n_channels=7\n",
    "xpixels=128\n",
    "ypixels=256\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "filename = Func_Train.data_unique_name_generator(model_data, reference_data, task_name, mm, date_start, date_end, variable, mask_type, laginensemble)\n",
    "data_unique_name=filename[:-4]\n",
    "\n",
    "training_unique_name = Func_Train.generate_training_unique_name(loss, Filters, LR, min_LR, lr_factor, lr_patience, BS, patience, val_split, epochs)\n",
    "\n",
    "print(data_unique_name, training_unique_name)\n",
    "\n",
    "# Create the training data (if doesn't exist)\n",
    "Func_Train.prepare_train(PPROJECT_DIR, TRAIN_FILES, ATMOS_DATA, filename, model_data, reference_data, task_name, mm, date_start, date_end, variable, mask_type, laginensemble, val_split, training_unique_name)\n",
    "\n",
    "# load the training data\n",
    "print(\"Loading training data...\")\n",
    "train_files=np.load(TRAIN_FILES+\"/\"+filename)\n",
    "\n",
    "train_x=train_files[\"train_x\"]\n",
    "train_y=train_files[\"train_y\"]\n",
    "train_m=train_files[\"train_m\"]\n",
    "val_x=train_files[\"val_x\"]\n",
    "val_y=train_files[\"val_y\"]\n",
    "val_m=train_files[\"val_m\"]\n",
    "\n",
    "model = Func_Train.UNET(xpixels, ypixels, n_channels, Filters)\n",
    "\n",
    "# Define optimizer and compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR, name='Adam')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['mse'])\n",
    "\n",
    "# Define the model checkpoint and early stopping callbacks\n",
    "model_path = PPROJECT_DIR+'/AI MODELS/00-UNET/'+training_unique_name+'.h5'\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(model_path, verbose=2, save_best_only=True, monitor='val_loss')\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=patience, monitor='val_loss'),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=PPROJECT_DIR+'/AI MODELS/00-UNET/'+training_unique_name)]\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=lr_factor, patience=lr_patience, min_lr=min_LR)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "# Train the model using train_x, train_y, train_m and val_x, val_y, val_m\n",
    "results = model.fit(train_x, train_y, validation_data=(val_x, val_y, val_m), \n",
    "                    batch_size=BS, epochs=epochs, verbose=1, \n",
    "                    callbacks=[callbacks, checkpointer, reduce_lr], sample_weight=train_m)\n",
    "# Save and plot the results\n",
    "print(\"Saving and plotting the results...\")\n",
    "RESULTS_DF=pd.DataFrame(results.history)\n",
    "RESULTS_DF.to_csv(DUMP_RESULTS+\"/\"+training_unique_name+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prc_env",
   "language": "python",
   "name": "conda_prc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
